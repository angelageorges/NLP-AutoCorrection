{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrFU9yzt1EMm",
        "outputId": "db327716-08d6-4a0f-e696-8098f6355c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.9.1)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20220524-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 22.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.7)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.23.0)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (9.0.0)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.7.0-py3-none-any.whl (10 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.5.2-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.0.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.5)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.10.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.10.0)\n",
            "Collecting autocommand\n",
            "  Downloading autocommand-2.2.1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.1.0)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.1.2-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (2022.6.2)\n",
            "Collecting cryptography>=36.0.0\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (2.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=6fe22a84c026aaf4b3750ba935d4807f0dbf9ed5299a2de77f672ed8cafed775\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/4e/9b67afd2430d55dee90bd57618dd7d899f1323e5852c465682\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp37-cp37m-linux_x86_64.whl size=99987 sha256=dd9b078b532d89e5b594f9e5e43ce2f240192180b6303e0d2a9631ed91c043e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/2d/67/2cb3f82e435fc8e055cb2761a15a0812bf086068f6fb835462\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=067bca49f0b9a301ff76fc6533e03c37020c54a7659a2aad55df643e2fdaa1cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=e01b81c3f1b8e5ce5a4699ff520dae9c3064fd39e45b21ebc46ec094b38b43de\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, jaraco.context, autocommand, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, pattern\n",
            "Successfully installed autocommand-2.2.1 backports.csv-1.0.7 cheroot-8.6.0 cherrypy-18.8.0 cryptography-38.0.3 feedparser-6.0.10 jaraco.classes-3.2.3 jaraco.collections-3.7.0 jaraco.context-4.1.2 jaraco.functools-3.5.2 jaraco.text-3.10.0 mysqlclient-2.1.1 pattern-3.6 pdfminer.six-20220524 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.0.2 zc.lockfile-2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 4.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=f2dde1be6f1dc294ae0dd9053fa39da115ba9cd1ef79284f91a39ab03ea16988\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textdistance\n",
            "  Downloading textdistance-4.5.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: textdistance\n",
            "Successfully installed textdistance-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pattern\n",
        "!pip install pyspellchecker\n",
        "!pip install autocorrect\n",
        "!pip install textblob\n",
        "!pip install textdistance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Preprocessing\n"
      ],
      "metadata": {
        "id": "TowrDtVP2hPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "5oLJg4XI2emM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = []\n"
      ],
      "metadata": {
        "id": "6rIpgk7-2aYr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/book.txt','r',encoding=\"utf8\") as f:\n",
        "    fp = f.read()\n",
        "    fp = fp.lower()\n",
        "    w = re.findall('\\w+', fp)"
      ],
      "metadata": {
        "id": "ICaiZe3o4Q1C"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v= set(w)"
      ],
      "metadata": {
        "id": "lVitPllK3RAF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The first 10 words in the dictionary are: \\n{w[0:10]}\")\n",
        "print(f\"The dictionary has {len(v)} words \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiMxm2El3Z5e",
        "outputId": "22607865-be13-4556-d0fd-425d53485138"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 10 words in the dictionary are: \n",
            "['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale']\n",
            "The dictionary has 17647 words \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To calculate frequency of dictionary words\n",
        "def get_count(words):\n",
        "  word_count = {}\n",
        "  for word in words:\n",
        "    if word in word_count:\n",
        "      word_count[word] += 1\n",
        "    else:\n",
        "      word_count[word] = 1\n",
        "\n",
        "  return word_count\n",
        "\n",
        "word_count = get_count(w)\n",
        "print(f\"There are {len(word_count)} key values pairs\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OI1QHkY4-QK",
        "outputId": "b7ad1cc2-3d25-41f2-dd98-0a09e23e08c2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 17647 key values pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To calculate probability that any word will appear\n",
        "def get_probs(word_count):\n",
        "  probs={}\n",
        "  m = sum(word_count.values())\n",
        "  for key in word_count.keys():\n",
        "    probs[key] = word_count[key]/m\n",
        "  return probs\n",
        "  "
      ],
      "metadata": {
        "id": "iVZ_G4W46Ywq"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the four edit functions\n",
        "1. Delete\n",
        "2. Switch\n",
        "3. Replace\n",
        "4. Insert"
      ],
      "metadata": {
        "id": "fXfqH3bJ68i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Delete a letter from a given word\n",
        "\n",
        "def deleteL(word):\n",
        "  delete_list = []\n",
        "  split_list = []\n",
        "  for i in range(len(word)):\n",
        "    split_list.append((word[0:i],word[i:]))\n",
        "  for a,b in split_list:\n",
        "    delete_list.append(a+b[1:])\n",
        "  return delete_list\n"
      ],
      "metadata": {
        "id": "looh7lIV67Vn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(deleteL(\"cans\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb4Yc68d8Iwu",
        "outputId": "2c60f2cf-5953-430d-b2c0-03dab359a59c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ans', 'cns', 'cas', 'can']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(deleteL(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B83Wyn348DeA",
        "outputId": "f0b4b6ee-7123-47d6-8353-e562898f293d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rash', 'tash', 'trsh', 'trah', 'tras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Switch - swaps two adjacent letters\n",
        "\n",
        "def switchL(word):\n",
        "  split_l = []\n",
        "  switch_l = []\n",
        "  for i in range(len(word)):\n",
        "    split_l.append((word[0:i], word[i:]))\n",
        "\n",
        "  switch_l = [a + b[1] + b[0] + b[2:] for a,b in split_l if len(b) >=2]\n",
        "  return switch_l\n",
        "\n"
      ],
      "metadata": {
        "id": "xQimKjoi8RB0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(switchL(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPv_Zggw9IVO",
        "outputId": "16aa296d-8bab-4c14-9e04-19423cbc7738"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rtash', 'tarsh', 'trsah', 'trahs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Replace - Changes one letter to another\n",
        "\n",
        "def replaceL(word):\n",
        "  split_l = []\n",
        "  replace_list = []\n",
        "  for i in range(len(word)):\n",
        "    split_l.append((word[0:i],word[i:]))\n",
        "  alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  replace_list = [a + l + b[1:] if len(b) > 1 else '' for a,b in split_l if b for l in alphabets]\n",
        "  return replace_list\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h8YOLtAV9OB-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(replaceL(\"can\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICkQQNea-AAD",
        "outputId": "91418db0-d9cb-4566-a2a5-57a4bdd9152f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aan', 'ban', 'can', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan', 'can', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Insert - adds extra characters\n",
        "\n",
        "def insertL(word):\n",
        "  split_l = []\n",
        "  insert_list = []\n",
        "  for i in range(len(word) + 1):\n",
        "    split_l.append((word[0:i], word[i:]))\n",
        "  letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  insert_list = [a + l + b for a, b in split_l for l in letters]\n",
        "  return insert_list\n"
      ],
      "metadata": {
        "id": "YGVcJgLb-I6D"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(insertL(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNdgNPHr-u33",
        "outputId": "cbf1f3c8-3c85-4cb6-b0a8-786c8cafdf31"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['atrash', 'btrash', 'ctrash', 'dtrash', 'etrash', 'ftrash', 'gtrash', 'htrash', 'itrash', 'jtrash', 'ktrash', 'ltrash', 'mtrash', 'ntrash', 'otrash', 'ptrash', 'qtrash', 'rtrash', 'strash', 'ttrash', 'utrash', 'vtrash', 'wtrash', 'xtrash', 'ytrash', 'ztrash', 'tarash', 'tbrash', 'tcrash', 'tdrash', 'terash', 'tfrash', 'tgrash', 'thrash', 'tirash', 'tjrash', 'tkrash', 'tlrash', 'tmrash', 'tnrash', 'torash', 'tprash', 'tqrash', 'trrash', 'tsrash', 'ttrash', 'turash', 'tvrash', 'twrash', 'txrash', 'tyrash', 'tzrash', 'traash', 'trbash', 'trcash', 'trdash', 'treash', 'trfash', 'trgash', 'trhash', 'triash', 'trjash', 'trkash', 'trlash', 'trmash', 'trnash', 'troash', 'trpash', 'trqash', 'trrash', 'trsash', 'trtash', 'truash', 'trvash', 'trwash', 'trxash', 'tryash', 'trzash', 'traash', 'trabsh', 'tracsh', 'tradsh', 'traesh', 'trafsh', 'tragsh', 'trahsh', 'traish', 'trajsh', 'traksh', 'tralsh', 'tramsh', 'transh', 'traosh', 'trapsh', 'traqsh', 'trarsh', 'trassh', 'tratsh', 'traush', 'travsh', 'trawsh', 'traxsh', 'traysh', 'trazsh', 'trasah', 'trasbh', 'trasch', 'trasdh', 'traseh', 'trasfh', 'trasgh', 'trashh', 'trasih', 'trasjh', 'traskh', 'traslh', 'trasmh', 'trasnh', 'trasoh', 'trasph', 'trasqh', 'trasrh', 'trassh', 'trasth', 'trasuh', 'trasvh', 'traswh', 'trasxh', 'trasyh', 'traszh', 'trasha', 'trashb', 'trashc', 'trashd', 'trashe', 'trashf', 'trashg', 'trashh', 'trashi', 'trashj', 'trashk', 'trashl', 'trashm', 'trashn', 'trasho', 'trashp', 'trashq', 'trashr', 'trashs', 'trasht', 'trashu', 'trashv', 'trashw', 'trashx', 'trashy', 'trashz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining all the functions"
      ],
      "metadata": {
        "id": "4Iu6RIwF-5dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word):\n",
        "  edit_set1 = set()\n",
        "  edit_set1.update(deleteL(word))\n",
        "  #if allow_switches:\n",
        "  edit_set1.update(switchL(word))\n",
        "  edit_set1.update(replaceL(word))\n",
        "  edit_set1.update(insertL(word))\n",
        "  return edit_set1\n"
      ],
      "metadata": {
        "id": "BNarutEJ_AxJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word):\n",
        "    edit_set2 = set()\n",
        "    edit_one = edit_one_letter(word)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = edit_one_letter(w)\n",
        "            edit_set2.update(edit_two)\n",
        "    return edit_set2"
      ],
      "metadata": {
        "id": "gpKbYSstAn7s"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2):\n",
        "    suggested_word = []\n",
        "    best_suggestion = []\n",
        "    suggested_word = list(\n",
        "        (word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(\n",
        "            vocab))\n",
        "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "    return best_suggestion"
      ],
      "metadata": {
        "id": "FfQ9wP_oAvUF"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "gA4EX4iaBH8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_word = input(\"Enter any word:\")\n",
        "probs = get_probs(word_count)\n",
        "tmp_corrections = get_corrections(my_word, probs, v, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq_6XL0dBKta",
        "outputId": "93fc7815-747c-4474-c716-040cd6a16b0b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter any word:pracess\n",
            "word 0: process, probability 0.000022\n"
          ]
        }
      ]
    }
  ]
}